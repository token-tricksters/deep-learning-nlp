{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Assignment 02a - Text Processing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"M2S6T2r24OoA","colab_type":"text"},"source":["# Assignment 02a - Text Representation, Mining, and Feature Extraction"]},{"cell_type":"markdown","metadata":{"id":"XxA2Cpjy4OoB","colab_type":"text"},"source":["# Exercises"]},{"cell_type":"markdown","metadata":{"id":"OzUyRtswAvTG","colab_type":"text"},"source":["## Get The Data\n","\n","Before starting this tutorial we will need some text files to process. To make it as easy as possible, the following two lines will download and extract the necessary data.\n"]},{"cell_type":"code","metadata":{"id":"u9lnFGqxlNyE","colab_type":"code","colab":{}},"source":["!pip install matplotlib nltk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4rrIIWYE5ye","colab_type":"code","colab":{}},"source":["!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1lZhU-6w8o5LeDqWRtW8-kfZLz2-nUflf' -O cdata.zip\n","!unzip -q ./cdata.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOJCAv_D4OoC","colab_type":"text"},"source":["## Part A"]},{"cell_type":"markdown","metadata":{"id":"fIpYkC694OoD","colab_type":"text"},"source":["1. How would you select a list with the first seven words in the `paragraph` variable? This will require two steps. Show your code and the output."]},{"cell_type":"code","metadata":{"id":"73fWB8qx4OoE","colab_type":"code","colab":{}},"source":["paragraph = \"It was a dark and stormy night; the rain fell in torrents — except at occasional intervals, when it was \" + \\\n","\"checked by a violent gust of wind which swept up the streets (for it is in London that our scene lies), rattling \" + \\\n","\"along the housetops, and fiercely agitating the scanty flame of the lamps that struggled against the darkness.\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TxGpGSn4OoI","colab_type":"text"},"source":["2. Split the following text into a list of *sentences*. Don't worry if one of your sentences is an empty string (''). Show the code and output."]},{"cell_type":"code","metadata":{"id":"CR9IuO4V4OoJ","colab_type":"code","colab":{}},"source":["text = \"The shows opens at Duckburg. After Donald Duck enlists in the navy, Uncle Scrooge has to take care of grand-nephews Huey, Dewey, and Louie. Uncle Scrooge brings the boys to the McDuck's mansion where they are presented to Duckworth, the butler. The nephews are forced to sleep in the attic\"\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PON_Ekmr4OoM","colab_type":"text"},"source":["3. Use the `nltk.word_tokenize` function on Frankenstein (*frankenstein.txt*), as shown in ALTA. What are tokens 39:67? *Hint: this is a full sentence. Include your code.*\n","4. Create a sample of only the tokens where the first character is an alphabetical character. In this sample, what are tokens 1215:1221? Again, this will be a sentence, but won't include punctuation as tokens. Include your code.\n","\n","```Python\n","with open('./cdata/frankenstein.txt') as f:\n","    frankensteinString = f.read()\n","    \n","frankensteinTokens = nltk.word_tokenize(frankensteinString)\n","cleanedTokens = [word.lower() for word in frankensteinTokens if word[0].isalpha()]\n","```\n"," "]},{"cell_type":"markdown","metadata":{"id":"wS3A-JtM4OoM","colab_type":"text"},"source":[" __For the next questions use the list of tokens that start with an alphabetical character.__\n"," \n"," \n","5. What are the ten most frequent words in this book? Create a frequency distribution of the words from question 4, then tabulate the top 10 words. Include your code.\n","6.  After case-folding, what are the ten most frequent words in this book? Include your code.\n","7.  Rewrite this list comprehension as a `for` loop (what ALTA called technique 1): `[word for word in listOfWords if word.find('-') >= 0]`. No output necessary, just the code, but feel free to test it out.\n","8.  We're going to use a customized stoplist. First, load the NLTK stoplist, and add the words 'could', 'would', 'upon', and 'yet' to the stoplist. What are the top ten case-folded words when stopping against the stoplist. Include your code and paste the tabulated output.\n"," \n","Using the autocomplete in Jupyter, you may notice that a list of tokens converted to a `FreqDist` object has more methods than just `tabulate()`. One really cool one is `plot()`.\n","\n","`plot` gives you a visualization of the top frequency words. However, you may notice that if you try to run it, the visualization doesn't show up.\n","\n","It _is_ created, but Jupyter just doesn't know that you want the visualization shown _within_ the notebook. To turn that option on, run the following line of code:"]},{"cell_type":"code","metadata":{"id":"XaZqsC6_4OoN","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_W9G8NM4OoP","colab_type":"text"},"source":["In a standard IDE you have to inlcude the library, provide the paramaters and call the show function.\n","\n","```Python\n","import matplotlib.pyplot as plt\n","plt.plot([1, 2, 3, 4])\n","plt.ylabel('some numbers')\n","plt.show()\n","```\n","More examples can be found [here](https://matplotlib.org/tutorials/introductory/pyplot.html)"]},{"cell_type":"markdown","metadata":{"id":"XUIzkh5N4OoP","colab_type":"text"},"source":["__Extra__\n","9. Write the code to plot the top forty stoplisted, lowercase words (from question 8).\n","10. Enter the first 5 concordances for the word \"monster\" in the original token list - the list straight from word_tokenize that included punctuation and numbers - narrowing the search to a 49-characters window. *Tip: See the docs for the concordance NLTK.*"]},{"cell_type":"markdown","metadata":{"id":"EbhIQxt34OoQ","colab_type":"text"},"source":["## Part B"]},{"cell_type":"markdown","metadata":{"id":"p9YXf26w4OoQ","colab_type":"text"},"source":["__Considering the corpus on `./cdata/frankenstein.txt`__\n","\n","```Python\n","with open('./cdata/frankenstein.txt') as f:\n","    frankensteinString = f.read()\n","    \n","frankensteinTokens = nltk.word_tokenize(frankensteinString)\n","cleanedTokens = [word for word in frankensteinTokens if word[0].isalpha()]\n","```"]},{"cell_type":"markdown","metadata":{"id":"vHjHie_04OoR","colab_type":"text"},"source":["1. How many words we have in `frankenstein.txt` considering the following scenarios. Plot the 10 most frequent words for each case.\n","   \n","   * Raw words (no pre-processing)\n","   * Lemmatized version\n","   * Stemmed version\n","   * Stop-word removal\n","   \n","\n","2. How does stop-words removal and case-folding (normalization) affect lemmatization (a) and stemming (b)? Plot/list the 10 most frequent words for our novel for each case ((a) and (b)).\n"]},{"cell_type":"markdown","metadata":{"id":"R7ytCSA34OoU","colab_type":"text"},"source":["##### Acknowledgements\n","\n","David Bamman - University of California Berkeley\n","\n","Peter Organisciak - University of Denver\n","\n","Stéfan Sinclair - McGill University"]},{"cell_type":"code","metadata":{"id":"G7V7oCuj4OoV","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}